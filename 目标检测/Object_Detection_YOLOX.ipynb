{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object_Detection_YOLOX.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1espug7fJbSkr1utwBzd996qNsjMqfeV3","authorship_tag":"ABX9TyON7I91s1li7/5gOZDdb+Re"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"88IKpvt1fI2J"},"source":["# 一、数据预处理\n","\n","将VOC标注的标注文件.xml转为COCO格式的.json文件\n","\n","在训练目标检测模型的时候一般使用labelimg标注的图像生产.xml格式的标注文件。有时候需要用到coco格式的json标注文件，在github找到了一个xml转json的脚本。(https://github.com/CivilNet/Gemfield/blob/master/src/python/pascal_voc_xml2json/pascal_voc_xml2json.py)\n","\n","执行该脚本会读取Annotations下的.xml文件并解析其中的类别及boundbox的坐标，最后生成instances.json的文件。\n","\n","原git的脚本不支持划分训练集测试集，也不能提前设定标签的索引。所以进行了改动，如下：\n","\n","（将所有图片和xml文件都放到同一个文件目录下，此处为/home/ouc/xyz/kdxf/train/TIFFImages/）"]},{"cell_type":"code","metadata":{"id":"yMb4mjRbfUqS"},"source":["#coding:utf-8\n"," \n","import os\n","import glob\n","import json\n","import shutil\n","import numpy as np\n","import xml.etree.ElementTree as ET\n"," \n","path2 = \".\"\n"," \n","START_BOUNDING_BOX_ID = 1\n"," \n","def get(root, name):\n","    return root.findall(name)\n"," \n","def get_and_check(root, name, length):\n","    vars = root.findall(name)\n","    if len(vars) == 0:\n","        raise NotImplementedError('Can not find %s in %s.'%(name, root.tag))\n","    if length > 0 and len(vars) != length:\n","        raise NotImplementedError('The size of %s is supposed to be %d, but is %d.'%(name, length, len(vars)))\n","    if length == 1:\n","        vars = vars[0]\n","    return vars\n"," \n","def convert(xml_list, json_file):\n","    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n","    categories = pre_define_categories.copy()\n","    bnd_id = START_BOUNDING_BOX_ID\n","    all_categories = {}\n","    for index, line in enumerate(xml_list):\n","        xml_f = line\n","        tree = ET.parse(xml_f)\n","        root = tree.getroot()\n","        \n","        filename = os.path.basename(xml_f)[:-4] + \".tif\"\n","        image_id = index\n","        size = get_and_check(root, 'size', 1)\n","        width = int(get_and_check(size, 'width', 1).text)\n","        height = int(get_and_check(size, 'height', 1).text)\n","        image = {'file_name': filename, 'height': height, 'width': width, 'id':image_id}\n","        json_dict['images'].append(image)\n","        ## Cruuently we do not support segmentation\n","        #  segmented = get_and_check(root, 'segmented', 1).text\n","        #  assert segmented == '0'\n","        for obj in get(root, 'object'):\n","            category = get_and_check(obj, 'name', 1).text\n","            if category in all_categories:\n","                all_categories[category] += 1\n","            else:\n","                all_categories[category] = 1\n","            if category not in categories:\n","                if only_care_pre_define_categories:\n","                    continue\n","                new_id = len(categories) + 1\n","                print(\"[warning] category '{}' not in 'pre_define_categories'({}), create new id: {} automatically\".format(category, pre_define_categories, new_id))\n","                categories[category] = new_id\n","            category_id = categories[category]\n","            bndbox = get_and_check(obj, 'bndbox', 1)\n","            xmin = int(float(get_and_check(bndbox, 'xmin', 1).text))\n","            ymin = int(float(get_and_check(bndbox, 'ymin', 1).text))\n","            xmax = int(float(get_and_check(bndbox, 'xmax', 1).text))\n","            ymax = int(float(get_and_check(bndbox, 'ymax', 1).text))\n","            assert(xmax > xmin), \"xmax <= xmin, {}\".format(line)\n","            assert(ymax > ymin), \"ymax <= ymin, {}\".format(line)\n","            o_width = abs(xmax - xmin)\n","            o_height = abs(ymax - ymin)\n","            ann = {'area': o_width*o_height, 'iscrowd': 0, 'image_id':\n","                   image_id, 'bbox':[xmin, ymin, o_width, o_height],\n","                   'category_id': category_id, 'id': bnd_id, 'ignore': 0,\n","                   'segmentation': []}\n","            json_dict['annotations'].append(ann)\n","            bnd_id = bnd_id + 1\n"," \n","    for cate, cid in categories.items():\n","        cat = {'supercategory': 'none', 'id': cid, 'name': cate}\n","        json_dict['categories'].append(cat)\n","    json_fp = open(json_file, 'w')\n","    json_str = json.dumps(json_dict)\n","    json_fp.write(json_str)\n","    json_fp.close()\n","    print(\"------------create {} done--------------\".format(json_file))\n","    print(\"find {} categories: {} -->>> your pre_define_categories {}: {}\".format(len(all_categories), all_categories.keys(), len(pre_define_categories), pre_define_categories.keys()))\n","    print(\"category: id --> {}\".format(categories))\n","    print(categories.keys())\n","    print(categories.values())\n"," \n","if __name__ == '__main__':\n","    classes = ['Port', 'Airport']\n","    pre_define_categories = {}\n","    for i, cls in enumerate(classes):\n","        pre_define_categories[cls] = i + 1\n","    only_care_pre_define_categories = True\n"," \n","    train_ratio = 0.9\n","    save_json_train = 'instances_train2014.json'\n","    save_json_val = 'instances_val2014.json'\n","    xml_dir = \"/home/ouc/xyz/kdxf/train/TIFFImages/\"\n"," \n","    xml_list = glob.glob(xml_dir + \"/*.xml\")\n","    xml_list = np.sort(xml_list)\n","    np.random.seed(100)\n","    np.random.shuffle(xml_list)\n"," \n","    train_num = int(len(xml_list)*train_ratio)\n","    xml_list_train = xml_list[:train_num]\n","    xml_list_val = xml_list[train_num:]\n"," \n","    convert(xml_list_train, save_json_train)\n","    convert(xml_list_val, save_json_val)\n"," \n","    if os.path.exists(path2 + \"/annotations\"):\n","        shutil.rmtree(path2 + \"/annotations\")\n","    os.makedirs(path2 + \"/annotations\")\n","    if os.path.exists(path2 + \"/images/train2014\"):\n","        shutil.rmtree(path2 + \"/images/train2014\")\n","    os.makedirs(path2 + \"/images/train2014\")\n","    if os.path.exists(path2 + \"/images/val2014\"):\n","        shutil.rmtree(path2 +\"/images/val2014\")\n","    os.makedirs(path2 + \"/images/val2014\")\n"," \n","    f1 = open(\"train.txt\", \"w\")\n","    for xml in xml_list_train:\n","        img = xml[:-4] + \".tif\"\n","        f1.write(os.path.basename(xml)[:-4] + \"\\n\")\n","        shutil.copyfile(img, path2 + \"/images/train2014/\" + os.path.basename(img))\n"," \n","    f2 = open(\"test.txt\", \"w\")\n","    for xml in xml_list_val:\n","        img = xml[:-4] + \".tif\"\n","        f2.write(os.path.basename(xml)[:-4] + \"\\n\") \n","        shutil.copyfile(img, path2 + \"/images/val2014/\" + os.path.basename(img))\n","    f1.close()\n","    f2.close()\n","    print(\"-------------------------------\")\n","    print(\"train number:\", len(xml_list_train))\n","    print(\"val number:\", len(xml_list_val))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hUaUSZBjnG5m"},"source":["# 二、安装 YOLOX\n","\n","1. 安装 YOLOX"]},{"cell_type":"code","metadata":{"id":"_c898Fe8kYRZ"},"source":["# 安装YOLOX\n","!git clone https://github.com/Megvii-BaseDetection/YOLOX.git\n","!pip3 install -r YOLOX/requirements.txt\n","!cd YOLOX && pip install -e ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fx8WTg-BpKZ1"},"source":["2. 安装 apex & pycocotools"]},{"cell_type":"code","metadata":{"id":"R2lSF4BelMiC"},"source":["# 安装apex\n","# !git clone https://github.com/NVIDIA/apex\n","# !cd apex && pip3 install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_exp\" --global-option=\"--cuda_ext\" ./\n","# 用上面方法安装apex失败，采取下方方式安装\n","!git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!pip install -v --no-cache-dir ./\n","# 安装pycocotools\n","!pip3 install cython\n","!pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfDbPBDJEQxs"},"source":["# 三、将数据集放到YOLOX/data/datasets下"]},{"cell_type":"code","metadata":{"id":"dqRYKkiULEJF"},"source":["# 在 YOLOX 文件夹下创建相关文件夹\n","!mkdir YOLOX/datasets/COCO\n","!mkdir YOLOX/datasets/COCO/annotations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8Gb6eqVG2be"},"source":["# 将 instances_train2014.json & instances_val2014.json 文件复制到 YOLOX 文件夹下 并重新取名\n","!cp 'instances_train2014.json' YOLOX/datasets/COCO/annotations/instances_train2017.json\n","!cp 'instances_val2014.json' YOLOX/datasets/COCO/annotations/instances_val2017.json\n","!ls YOLOX/datasets/COCO/annotations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aag7f2gTJQ4I"},"source":["# 将数据集文件夹 映射 到 YOLOX 文件夹下，并重新取名（映射不占多余空间）\n","!ln -s '/home/ouc/xyz/kdxf/train/TIFFImages/' YOLOX/datasets/COCO/train2017\n","!ln -s '/home/ouc/xyz/kdxf/train/TIFFImages/' YOLOX/datasets/COCO/val2017"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYZ-XEq7KMpD"},"source":["# 四、准备我们自己的 YOLOX exp & cococlasses\n","1. 设置我们自己的 exp, 这里用 yolox_x"]},{"cell_type":"code","metadata":{"id":"x0LApuEBKepq"},"source":["!echo \"        self.num_classes = 2\" >> YOLOX/exps/default/yolox_x.py # 修改类别数\n","!echo \"        self.max_epoch = 10\" >> YOLOX/exps/default/yolox_x.py # 修改epochs\n","!echo \"        self.eval_interval = 1\" >> YOLOX/exps/default/yolox_x.py\n","!echo \"        self.warmup_epochs = 2\" >> YOLOX/exps/default/yolox_x.py\n","\n","!cat YOLOX/exps/default/yolox_x.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnqPXOFHNzZO"},"source":["2. 设置 coco_classes"]},{"cell_type":"code","metadata":{"id":"OW4dyQmnNxAX"},"source":["!echo \"COCO_CLASSES = ('Port','Airport')\" > \"YOLOX/yolox/data/datasets/coco_classes.py\"\n","!cat YOLOX/yolox/data/datasets/coco_classes.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Pdfr7kJOCG3"},"source":["# 五、下载预训练模型"]},{"cell_type":"code","metadata":{"id":"wpz4-krbOJ5J"},"source":["!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_x.pth\n","!mv yolox_x.pth yolox_x.pth.tar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSYoAsZ9OokT"},"source":["# 六、用预训练模型进行训练"]},{"cell_type":"code","metadata":{"id":"4pqR-NlZOt5M"},"source":["!python YOLOX/tools/train.py -f YOLOX/exps/default/yolox_x.py -d 1 -b 4 --fp16 -o -c yolox_x.pth.tar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pjqooqLZ8Gy"},"source":["# 七、评估"]},{"cell_type":"code","metadata":{"id":"3e6syca65sZG"},"source":["!python YOLOX/tools/eval.py -f YOLOX/exps/default/yolox_x.py -c YOLOX_outputs/yolox_x/latest_ckpt.pth -b 4 -d 1 --conf 0.001 --fp16 --fuse"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-lqF0YBa9wA"},"source":["# 八、可视化 demo"]},{"cell_type":"code","metadata":{"id":"Opi6aG9VbGkC"},"source":["!mv YOLOX_outputs/yolox_x/latest_ckpt.pth YOLOX_outputs/yolox_x/latest_ckpt.pth.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZAOXwt8bN9r"},"source":["!python YOLOX/tools/demo.py image -n yolox-x -c YOLOX_outputs/yolox_x/latest_ckpt.pth.tar --path '/home/ouc/xyz/kdxf/train/TIFFImages/0.tif' --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B2s78tjcdEG3"},"source":["# 九、Output & Submit\n","1. 定义 predict 函数来返回 output"]},{"cell_type":"code","metadata":{"id":"4ws-bt0UdRd3"},"source":["def predict(pth,jpg):\n","    %cd YOLOX\n","    from yolox.exp import get_exp\n","    from loguru import logger\n","    from yolox.utils import fuse_model, get_model_info, postprocess, vis\n","    from yolox.data.data_augment import preproc\n","    import torch,cv2\n","    exp=get_exp('/exps/default/yolox_x.py','yolox_x')\n","    model = exp.get_model()\n","    #logger.info(\"Model Summary: {}\".format(get_model_info(model, exp.test_size)))\n","    model.cuda()\n","    model.eval()\n","    ckpt_file=pth\n","    ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n","    model.load_state_dict(ckpt[\"model\"])\n","    model = fuse_model(model)\n","    img = cv2.imread(jpg)\n","    img, ratio = preproc(img, exp.test_size, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # test_size = (640, 640)\n","    img = torch.from_numpy(img).unsqueeze(0)\n","    img = img.cuda()\n","    outputs = model(img)\n","    #outputs = postprocess(outputs, 5, exp.test_conf, exp.nmsthre) #test_conf = 0.01 nmsthre = 0.65\n","    outputs = postprocess(outputs, 5, 0.25 , 0.45)\n","    output = outputs[0]\n","    if output==None:\n","        %cd ..\n","        return None,None,None\n","    output = output.cpu()\n","    bboxes = output[:, 0:4]\n","    bboxes=bboxes/ratio\n","    cls = output[:, 6]\n","    scores = output[:, 4] * output[:, 5]\n","    %cd ..\n","    return bboxes,cls,scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwWbZdZAdo5z"},"source":["pth='YOLOX_outputs/yolox_x/latest_ckpt.pth.tar'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSGbDGXud02Q"},"source":["2. 用 output 来返回 submissions"]}]}